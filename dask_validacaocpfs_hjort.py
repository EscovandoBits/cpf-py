# -*- coding: utf-8 -*-
"""Dask-ValidacaoCPFs-Hjort.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1T7aMBFqOSsbB7BWPtmJZScO9o3CaUc_y

# Validação de CPFs - Experimento de validação paralelizada com Dask

https://colab.research.google.com/drive/1T7aMBFqOSsbB7BWPtmJZScO9o3CaUc_y?usp=sharing

# Preparo dos dados

## Geração de números aleatórios
"""

import numpy as np

# Geração de números inteiros com até 9 dígitos
# para posterior cálculo de DV usando algoritmo
# de validação de CPFs
np.random.seed(42)

# quantidade de números a serem gerados
#num_amostras = 200
#num_amostras = int(10e6)
num_amostras = int(100e6)

# Geração das amostras (números inteiros com até 11 dígitos)
amostras = np.random.randint(99999999999, size=num_amostras)

# exibir informações do array de amostra
print('Amostra de valores:\n', amostras)
print('Quantidade de itens:', len(amostras))
print('Tamanho em memória: %.1f MB' % (amostras.size * amostras.itemsize / 1024 / 1024))

"""## Geração de múltiplos arquivos"""

# quantidade de partições (arquivos a serem gerados)
qtd_particoes = 20

# dividir o vetor nas diversas partições
amostras_particoes = np.array_split(amostras, qtd_particoes)
amostras_particoes[0][:10]

!rm -rf arquivos && mkdir arquivos

# gerar um arquivo de texto para cada partição
for i in range(len(amostras_particoes)):
  arq = "arquivos/%03d.txt" % (i+1)
  print(arq)
  np.savetxt(arq, amostras_particoes[i], fmt='%d')

!ls -lah arquivos/*

del amostras_particoes

"""# Criação da função de validação

## Função de validação de dígito verificador de CPF

> Retorna True caso o número de CPF seja válido, False caso contrário.
"""

# Baseado no algoritmo em Linguagem C:
# https://github.com/EscovandoBits/cpf/blob/main/cpf.c

# verifica se um número de CPF é válido
def cpf_valido(n):
  #print('cpf_valido(%011d)' % n)

  # extrair dígitos verificadores
  dv = n % 100
  d10 = dv // 10
  d11 = dv % 10

  # calcular penúltimo dígito
  v1 = 0
  r = n // 100
  i = 9
  while True:
    d = r % 10
    r = r // 10
    v1 += i * d
    i = i - 1
    if not (r > 0 and i > 0):
      break
  v1 = (v1 % 11) % 10
  if (v1 != d10):
    return False

  # calcular último dígito
  v2 = 0
  r = n // 100
  i = 8
  while True:
    d = r % 10
    r = r // 10
    v2 += i * d
    i = i - 1
    if not (r > 0 and i > 0):
      break
  v2 += 9 * v1
  v2 = (v2 % 11) % 10
  if (v2 != d11):
    return False

  return True

# teste de execução da função
for num in [11111111111, 11111111112, 22222222222, 22222222221, 123]:
  print('cpf_valido(%011d)? %s' % (num, cpf_valido(num)))

vcpf_valido = np.vectorize(cpf_valido)
vcpf_valido

"""# Processamento sequencial

## Aplicação em arrays
"""

a = amostras[:5]
a

b = [cpf_valido(n) for n in a]
b

def div7b(num):
  #return ((num % 7 == 0) & (num / 1 == num)).any()
  #return ((num % 7 == 0) & (num / 1 == num)).all()
  #return (num % 7 == 0) and (num / 1 == num)
  return num % 7 == 0

div7b(a)

a[div7b(a)]

vdiv7b = np.vectorize(div7b)
vdiv7b

vdiv7b(a)

a[vdiv7b(a)]

"""# Processamento parelizado

## Inicialização do ambiente Dask
"""

import dask
import dask.array as da

from dask.distributed import Client

client = Client(n_workers=4, memory_limit="2.5GB")
#client = Client(n_workers=8)
client

"""## Criação dos dados

### Via vetor na memória
"""

# criação do vetor de forma distribuída a partir da memória
numeros_distribuidos = da.from_array(amostras, chunks=('auto',))
numeros_distribuidos

del amostras

"""### Via arquivos de texto"""

import glob

arquivos = []
for arquivo in glob.glob("arquivos/*.txt"):
  d = dask.delayed(np.loadtxt)(arquivo)
  arquivos.append(da.from_delayed(d, (np.nan,), dtype=np.int64))

# criação do vetor a partir dos arquivos de forma preguiçosa
numeros_distribuidos = da.concatenate(arquivos, allow_unknown_chunksizes=True)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# numeros_distribuidos.compute_chunk_sizes()

"""## Filtragem com _map_blocks_"""

def filtrar_cpfs_validos(numeros):
  return numeros[vcpf_valido(numeros)]

validos = da.map_blocks(filtrar_cpfs_validos,
                           numeros_distribuidos,
                           meta=np.array((), dtype=np.int64))
validos

validos.dask

validos.visualize()

# Commented out IPython magic to ensure Python compatibility.
# %%time
# cpfs_validos = validos.compute().astype(np.int64)

"""## Filtragem com _filter_"""

# FIXME: não funcionou...

#validos = da.where(vcpf_valido(numeros_distribuidos), numeros_distribuidos, 0)
#validos

"""## Exibição do resultado"""

# exibição do resultado
cpfs_validos[:10]

print("Do total de %d números da amostra, apenas %d são CPFs válidos (%.2f%%)." % (
    len(numeros_distribuidos), len(cpfs_validos),
    len(cpfs_validos) / len(numeros_distribuidos) * 100))

"""## Finalização do ambiente Dask"""

client.close()